<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[CarrollOps]]></title>
  <link href="http://www.carrollops.com/atom.xml" rel="self"/>
  <link href="http://www.carrollops.com/"/>
  <updated>2012-08-07T16:08:37-07:00</updated>
  <id>http://www.carrollops.com/</id>
  <author>
    <name><![CDATA[Jeremy Carroll]]></name>
    <email><![CDATA[phobos182 gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hadoop Fair Scheduler monitoring]]></title>
    <link href="http://www.carrollops.com/blog/2012/08/07/hadoop-fair-scheduler-monitoring/"/>
    <updated>2012-08-07T15:23:00-07:00</updated>
    <id>http://www.carrollops.com/blog/2012/08/07/hadoop-fair-scheduler-monitoring</id>
    <content type="html"><![CDATA[<p>So today I received a request to help debug fair scheduler performance on one of our large Hadoop clusters. Normally this is the point where I would point to installing a tool like Cloudera Manager, but we do not have CM running anywhere within our environment. So I took a quick look around GitHub to see if anybody has written any scripts to monitor the fair scheduler allocations and found nothing. We currently have monitoring on the Hadoop / HDFS level, but are lacking visibility at the individual scheduler / pool level. Questions arise such as this that I cannot answer without a cool made-up story.</p>

<ul>
<li>My job ran very slow last night, can you take a look at the cluster to see if anything is wrong?</li>
<li>This set of Oozie jobs normally takes 2 hours, but over the past few days it has been taking 4 hours easy run, why is that?</li>
<li>Can you check the network? Looks like my jobs have been running very slowly.</li>
</ul>


<p>Now at this point, I check the regular cluster health with our fleet of monitoring tools based on Graphite / OpenTSDB. Looking at HDFS health, I see no instances of failed datanodes, 100 mbit links, errors in the log files, et al. While looking at basic hadoop-metrics from our logging context, I see that the cluster is almost always 100% utilized on map slots / reduce slots. The next obvious question is &#8216;Who is running jobs stealing my resources?&#8217;. Before I can start to create fair-share policies, and pick winners and losers of precious cluster resources via preemption I need to know demand. I need to know how many jobs are running in each pool, and how many slots they require to finish there tasks. I would also love to monitor preemption requests to see when pools start killing other tasks to meet their fair-share or min-share. I set out to create a simple tool to query the http://jobtracker:50030/scheduler?advanced web interface on a timer, and send this metadata to Graphite / OpenTSDB on a real-time basis. I could then create visualizations to see demand and allocation to help craft fair share policies. It&#8217;s not perfect as it does not look at individual job performance (Input splits, min / max task completion time) but is really helpful on a high level.</p>

<p>I wanted something quick and easy to get done, so I took about 2 hours to create a Ruby Mechanize script to screen scrape the jobtracker fair-scheduler page. I then turn the output into a KeyValue format that I can use with OpenTSDB / Graphite. I did not want to create a lot of unique keys due to issues with Graphite creating a Whisper database per unique point. So capturing job-name, task-id is unacceptable. I instead aggregate metrics by user, or pool. In the case of our cluster job pool names are users. So I aggreagte the metrics by pool name, then send off to our visualiation system for further planning.</p>

<ul>
<li><a href="https://github.com/phobos182/hadoop-hbase-tools">https://github.com/phobos182/hadoop-hbase-tools</a></li>
</ul>


<p>I create a project above if you would like to hack on the code. Currently I am using Diamond <a href="https://github.com/BrightcoveOS/Diamond">https://github.com/BrightcoveOS/Diamond</a> to schedule checks via the UserScriptsCollector for ruby programs. It wants Key + Value, and fills in the date for you based on your scheduler. I can then send the metrics to both OpenTSDB + Graphite with the same system via Handlers. Below is some graphs of the things you can do with this information.</p>

<p><img class="left" src="http://www.carrollops.com/images/graphite_fair_scheduler.png" width="351" height="140" title="'Fair scheduler' #2" >
As you can see by the graph, it details a nice break down of slots utilization by fair scheduler pool. In this image, 3 different pools are racing for resources as the cluster is 100% utilized. You can dive into other metrics such as total tasks scheduled (map / reduce) vs. resources available at that time. Let me know if you find this tool helpful. Pull requests are always welcome.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Open sourcing some work]]></title>
    <link href="http://www.carrollops.com/blog/2012/08/06/open-sourcing-some-work/"/>
    <updated>2012-08-06T12:37:00-07:00</updated>
    <id>http://www.carrollops.com/blog/2012/08/06/open-sourcing-some-work</id>
    <content type="html"><![CDATA[<p>I&#8217;ve made it a point to start contributing more of my work back to the open source community i&#8217;ve gained so much from. So in next few days with permission from my employer, I am going to start contributing some simple tools that have made my life easier over here at Klout. Here is a list of some of the things i&#8217;m working on.</p>

<ul>
<li>Storm Puppet module</li>
<li>Storm debian packaging</li>
<li>HBase rolling compact tool with ZooKeeper locks</li>
<li>HBase major_compaction script with ZooKeeper locks</li>
<li>HBase metrics collection script</li>
<li>HBase per-table load balancing calculation script</li>
<li>Hadoop GraphiteClient context</li>
<li>Kafka JMX Monitoring script</li>
<li>Diamond handler for Kafka</li>
<li>OpenTSDB GnuPlot options</li>
<li>MCollective Monit agent</li>
<li>Hadoop hiera puppet module</li>
<li>HBase hiera puppet module</li>
</ul>

]]></content>
  </entry>
  
</feed>
